@ARTICLE{
   iet:/content/conferences/10.1049/cp.2017.0154,
   author = { Huy-Hieu Pham},
   affiliation = {Centre d&apos;Etudes et d&apos;Expertise sur les Risques, I&apos;Environ., la Mobilite et l&apos;Amenagement},
   author = {L. Khoudour},
   affiliation = {Centre d&apos;Etudes et d&apos;Expertise sur les Risques, I&apos;Environ., la Mobilite et l&apos;Amenagement},
   author = {A. Crouzil},
   affiliation = {Inst. de Rech. en Inf. de Toulouse, Univ. Paul Sabatier, Toulouse},
   author = {P. Zegers},
   affiliation = {Fac. de Ing. y Cienc. Aplic., Univ. de Los Andes, Los Andes},
   author = {S.A. Velastin},
   affiliation = {Dept. of Comput. Sci., Univ. Carlos III of Madrid, Leganes},
   keywords = {deep learning algorithms;artificial intelligent systems;skeleton data;image classification;skeleton movement;image feature extraction;vision-related recognition tasks;video datasets;3D-arrays;deep residual neural networks;RGB images space;computer vision;Kinect sensor;automatic human action recognition;ResNets;},
   language = {English},
   abstract = {Automatic human action recognition is indispensable for almost artificial intelligent systems such as video surveillance, human-computer interfaces, video retrieval, etc. Despite a lot of progresses, recognizing actions in a unknown video is still a challenging task in computer vision. Recently, deep learning algorithms has proved its great potential in many vision-related recognition tasks. In this paper, we propose the use of Deep Residual Neural Networks (ResNets) to learn and recognize human action from skeleton data provided by Kinect sensor. Firstly, the body joint coordinates are transformed into 3D-arrays and saved in RGB images space. Five different deep learning models based on ResNet have been designed to extract image features and classify them into classes. Experiments are conducted on two public video datasets for human action recognition containing various challenges. The results show that our method achieves the state-of-the-art performance comparing with existing approaches.},
   title = {Learning and recognizing human action from skeleton movement with deep residual neural networks},
   journal = {IET Conference Proceedings},
   year = {2017},
   month = {January},
   pages = {25 (6 .)-25 (6 .)(1)},
   publisher ={Institution of Engineering and Technology},
   url = {https://digital-library.theiet.org/content/conferences/10.1049/cp.2017.0154}
}

